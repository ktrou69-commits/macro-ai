#!/usr/bin/env python3
"""
cnn_detector.py
–î–µ—Ç–µ–∫—Ç–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ CNN
"""

import sys
from pathlib import Path
import numpy as np
import cv2
from typing import Optional, Tuple, List

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import tensorflow as tf
    from tensorflow import keras
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("‚ö†Ô∏è  TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. CNN –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")


class CNNDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ CNN"""
    
    def __init__(self, models_dir: str = "learning/models/cnn"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        
        Args:
            models_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        self.models_dir = Path(models_dir)
        self.models_cache = {}  # –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.img_size = (64, 64)
        
        if not TF_AVAILABLE:
            raise ImportError("TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def load_model(self, template_id: str) -> Optional[keras.Model]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        
        Args:
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            
        Returns:
            –ú–æ–¥–µ–ª—å –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if template_id in self.models_cache:
            return self.models_cache[template_id]
        
        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        model_path = self.models_dir / f"{template_id.replace('/', '_')}_cnn.keras"
        
        if not model_path.exists():
            return None
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            model = keras.models.load_model(model_path)
            
            # –ö—ç—à–∏—Ä—É–µ–º
            self.models_cache[template_id] = model
            
            return model
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {template_id}: {e}")
            return None
    
    def preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            img: –í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            
        Returns:
            –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if len(img.shape) == 3:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Resize –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        img = cv2.resize(img, self.img_size)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 1]
        img = img.astype(np.float32) / 255.0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª –∏ batch dimension
        img = np.expand_dims(img, axis=-1)
        img = np.expand_dims(img, axis=0)
        
        return img
    
    def detect(
        self, 
        screenshot: np.ndarray, 
        template_id: str,
        threshold: float = 0.8,
        stride: int = 16
    ) -> Tuple[bool, Optional[Tuple[int, int]], float]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ
        
        Args:
            screenshot: –°–∫—Ä–∏–Ω—à–æ—Ç —ç–∫—Ä–∞–Ω–∞
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0-1)
            stride: –®–∞–≥ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞
            
        Returns:
            (–Ω–∞–π–¥–µ–Ω–æ, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = self.load_model(template_id)
        
        if model is None:
            return False, None, 0.0
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        if len(screenshot.shape) == 3:
            gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)
        else:
            gray = screenshot
        
        h, w = gray.shape
        window_h, window_w = self.img_size
        
        best_score = 0.0
        best_location = None
        
        # –°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ
        for y in range(0, h - window_h, stride):
            for x in range(0, w - window_w, stride):
                # –í—ã—Ä–µ–∑–∞–µ–º –æ–∫–Ω–æ
                window = gray[y:y+window_h, x:x+window_w]
                
                # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
                processed = self.preprocess_image(window)
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                prediction = model.predict(processed, verbose=0)[0][0]
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if prediction > best_score:
                    best_score = prediction
                    best_location = (x + window_w // 2, y + window_h // 2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥
        if best_score >= threshold:
            return True, best_location, float(best_score)
        else:
            return False, None, float(best_score)
    
    def detect_multi_scale(
        self,
        screenshot: np.ndarray,
        template_id: str,
        threshold: float = 0.8,
        scales: List[float] = [0.5, 0.75, 1.0, 1.25, 1.5]
    ) -> Tuple[bool, Optional[Tuple[int, int]], float]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —ç–ª–µ–º–µ–Ω—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö
        
        Args:
            screenshot: –°–∫—Ä–∏–Ω—à–æ—Ç —ç–∫—Ä–∞–Ω–∞
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            scales: –ú–∞—Å—à—Ç–∞–±—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            (–Ω–∞–π–¥–µ–Ω–æ, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        best_score = 0.0
        best_location = None
        best_scale = 1.0
        
        for scale in scales:
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            scaled_h = int(screenshot.shape[0] * scale)
            scaled_w = int(screenshot.shape[1] * scale)
            scaled = cv2.resize(screenshot, (scaled_w, scaled_h))
            
            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º
            found, location, score = self.detect(scaled, template_id, threshold=threshold)
            
            if found and score > best_score:
                best_score = score
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
                best_location = (int(location[0] / scale), int(location[1] / scale))
                best_scale = scale
        
        if best_location:
            return True, best_location, float(best_score)
        else:
            return False, None, float(best_score)
    
    def detect_fast(
        self,
        screenshot: np.ndarray,
        template_id: str,
        threshold: float = 0.8,
        grid_size: int = 8
    ) -> Tuple[bool, Optional[Tuple[int, int]], float]:
        """
        –ë—ã—Å—Ç—Ä–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥—Ä—É–±–æ–π —Å–µ—Ç–∫–∏
        
        Args:
            screenshot: –°–∫—Ä–∏–Ω—à–æ—Ç —ç–∫—Ä–∞–Ω–∞
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            grid_size: –†–∞–∑–º–µ—Ä —Å–µ—Ç–∫–∏ –¥–ª—è –≥—Ä—É–±–æ–≥–æ –ø–æ–∏—Å–∫–∞
            
        Returns:
            (–Ω–∞–π–¥–µ–Ω–æ, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = self.load_model(template_id)
        
        if model is None:
            return False, None, 0.0
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        if len(screenshot.shape) == 3:
            gray = cv2.cvtColor(screenshot, cv2.COLOR_BGR2GRAY)
        else:
            gray = screenshot
        
        h, w = gray.shape
        window_h, window_w = self.img_size
        
        # –ì—Ä—É–±—ã–π –ø–æ–∏—Å–∫
        stride_coarse = max(window_w // 2, 32)
        best_score = 0.0
        best_location = None
        
        candidates = []
        
        for y in range(0, h - window_h, stride_coarse):
            for x in range(0, w - window_w, stride_coarse):
                window = gray[y:y+window_h, x:x+window_w]
                processed = self.preprocess_image(window)
                prediction = model.predict(processed, verbose=0)[0][0]
                
                if prediction > threshold * 0.7:  # –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                    candidates.append((x, y, prediction))
        
        if not candidates:
            return False, None, 0.0
        
        # –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ –≤–æ–∫—Ä—É–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        stride_fine = 8
        
        for cx, cy, _ in candidates:
            # –û–±–ª–∞—Å—Ç—å –≤–æ–∫—Ä—É–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            x_start = max(0, cx - stride_coarse)
            x_end = min(w - window_w, cx + stride_coarse)
            y_start = max(0, cy - stride_coarse)
            y_end = min(h - window_h, cy + stride_coarse)
            
            for y in range(y_start, y_end, stride_fine):
                for x in range(x_start, x_end, stride_fine):
                    window = gray[y:y+window_h, x:x+window_w]
                    processed = self.preprocess_image(window)
                    prediction = model.predict(processed, verbose=0)[0][0]
                    
                    if prediction > best_score:
                        best_score = prediction
                        best_location = (x + window_w // 2, y + window_h // 2)
        
        if best_score >= threshold:
            return True, best_location, float(best_score)
        else:
            return False, None, float(best_score)
    
    def is_model_available(self, template_id: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        
        Args:
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            
        Returns:
            True –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞
        """
        model_path = self.models_dir / f"{template_id.replace('/', '_')}_cnn.keras"
        return model_path.exists()
    
    def get_available_models(self) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
        Returns:
            –°–ø–∏—Å–æ–∫ ID —à–∞–±–ª–æ–Ω–æ–≤
        """
        models = []
        
        if not self.models_dir.exists():
            return models
        
        for model_file in self.models_dir.glob("*_cnn.keras"):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º template_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            template_id = model_file.stem.replace('_cnn', '').replace('_', '/')
            models.append(template_id)
        
        return models
    
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π"""
        self.models_cache.clear()


def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞"""
    import pyautogui
    
    print("üîç –¢–µ—Å—Ç CNN –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞")
    print("="*60)
    
    detector = CNNDetector()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
    models = detector.get_available_models()
    
    if not models:
        print("‚ùå –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏ –º–æ–¥–µ–ª—å: python3 learning/cnn_trainer.py")
        return
    
    print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {len(models)}")
    for i, model_id in enumerate(models, 1):
        print(f"  {i}. {model_id}")
    
    # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
    try:
        choice = int(input("\n–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å (–Ω–æ–º–µ—Ä): ").strip())
        if 1 <= choice <= len(models):
            template_id = models[choice - 1]
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä")
            return
    except ValueError:
        print("‚ùå –í–≤–µ–¥–∏ —á–∏—Å–ª–æ")
        return
    
    print(f"\nüîç –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {template_id}")
    print("üì∏ –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç...")
    
    # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç
    screenshot = pyautogui.screenshot()
    screenshot = np.array(screenshot)
    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)
    
    # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º
    print("üß† –ó–∞–ø—É—Å–∫ CNN –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")
    found, location, confidence = detector.detect_fast(screenshot, template_id)
    
    if found:
        print(f"\n‚úÖ –ù–ê–ô–î–ï–ù–û!")
        print(f"   –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {location}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence*100:.1f}%")
    else:
        print(f"\n‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence*100:.1f}%")


if __name__ == '__main__':
    main()
