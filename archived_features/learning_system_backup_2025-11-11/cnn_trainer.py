#!/usr/bin/env python3
"""
cnn_trainer.py
–û–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
"""

import sys
import os
from pathlib import Path
import numpy as np
import cv2
import argparse
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    print("‚ùå TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏: pip3 install tensorflow")
    sys.exit(1)

from learning import LearningSystem


class CNNTrainer:
    """–¢—Ä–µ–Ω–µ—Ä CNN –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, learning_system: LearningSystem = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
        
        Args:
            learning_system: –°–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        """
        self.learning_system = learning_system or LearningSystem(db_path="learning/memory.db")
        self.models_dir = Path("learning/models/cnn")
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.img_size = (64, 64)  # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.batch_size = 32
        self.epochs = 50
    
    def create_cnn_model(self, input_shape=(64, 64, 1)) -> keras.Model:
        """
        –°–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É CNN –º–æ–¥–µ–ª–∏
        
        Args:
            input_shape: –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        model = keras.Sequential([
            # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            layers.Input(shape=input_shape),
            
            # –ë–ª–æ–∫ 1: –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # –ë–ª–æ–∫ 2: –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # –ë–ª–æ–∫ 3: –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.BatchNormalization(),
            layers.MaxPooling2D((2, 2)),
            layers.Dropout(0.25),
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            layers.Flatten(),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(1, activation='sigmoid')  # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        ])
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]
        )
        
        return model
    
    def prepare_training_data(self, template_id: str, min_examples: int = 50):
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            min_examples: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
            
        Returns:
            X_train, X_val, y_train, y_val –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        """
        print(f"\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {template_id}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        examples = self.learning_system.db.get_examples(template_id)
        
        if len(examples) < min_examples:
            print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(examples)} < {min_examples}")
            print(f"üí° –ó–∞–ø—É—Å—Ç–∏ –º–∞–∫—Ä–æ—Å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
            return None
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
        positives = [e for e in examples if e['success'] and e['screenshot'] is not None]
        negatives = [e for e in examples if not e['success'] and e['screenshot'] is not None]
        
        print(f"   ‚úÖ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(positives)}")
        print(f"   ‚ùå –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(negatives)}")
        
        if len(positives) < 10 or len(negatives) < 10:
            print(f"‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–¥–Ω–æ–≥–æ –∏–∑ –∫–ª–∞—Å—Å–æ–≤")
            return None
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã
        min_count = min(len(positives), len(negatives))
        positives = positives[:min_count]
        negatives = negatives[:min_count]
        
        print(f"   ‚öñÔ∏è  –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ: {min_count} –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        X = []
        y = []
        
        for example in positives:
            img = self._preprocess_image(example['screenshot'])
            if img is not None:
                X.append(img)
                y.append(1)  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å
        
        for example in negatives:
            img = self._preprocess_image(example['screenshot'])
            if img is not None:
                X.append(img)
                y.append(0)  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å
        
        X = np.array(X)
        y = np.array(y)
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º
        indices = np.random.permutation(len(X))
        X = X[indices]
        y = y[indices]
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val (80/20)
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X[:split_idx], X[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        
        print(f"   üì¶ Train: {len(X_train)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        print(f"   üì¶ Val: {len(X_val)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        return X_train, X_val, y_train, y_val
    
    def _preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """
        –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            img: –í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            
        Returns:
            –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if len(img.shape) == 3:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # Resize –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            img = cv2.resize(img, self.img_size)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 1]
            img = img.astype(np.float32) / 255.0
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª
            img = np.expand_dims(img, axis=-1)
            
            return img
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return None
    
    def train(self, template_id: str, epochs: int = None, batch_size: int = None):
        """
        –û–±—É—á–∞–µ—Ç CNN –º–æ–¥–µ–ª—å –¥–ª—è —à–∞–±–ª–æ–Ω–∞
        
        Args:
            template_id: ID —à–∞–±–ª–æ–Ω–∞
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é self.epochs)
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é self.batch_size)
            
        Returns:
            –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∏–ª–∏ None
        """
        print(f"\n{'='*60}")
        print(f"üß† –û–ë–£–ß–ï–ù–ò–ï CNN: {template_id}")
        print(f"{'='*60}")
        
        epochs = epochs or self.epochs
        batch_size = batch_size or self.batch_size
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        data = self.prepare_training_data(template_id)
        if data is None:
            return None
        
        X_train, X_val, y_train, y_val = data
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        print(f"\nüèóÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        model = self.create_cnn_model(input_shape=(*self.img_size, 1))
        
        print(f"\nüìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
        model.summary()
        
        # Callbacks
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7
            )
        ]
        
        # –û–±—É—á–µ–Ω–∏–µ
        print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
        print(f"   –≠–ø–æ—Ö: {epochs}")
        print(f"   Batch size: {batch_size}")
        
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        # –û—Ü–µ–Ω–∫–∞
        print(f"\nüìà –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...")
        train_loss, train_acc, train_prec, train_rec = model.evaluate(X_train, y_train, verbose=0)
        val_loss, val_acc, val_prec, val_rec = model.evaluate(X_val, y_val, verbose=0)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   Train - Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}%, Prec: {train_prec*100:.2f}%, Rec: {train_rec*100:.2f}%")
        print(f"   Val   - Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%, Prec: {val_prec*100:.2f}%, Rec: {val_rec*100:.2f}%")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        model_path = self.models_dir / f"{template_id.replace('/', '_')}_cnn.keras"
        model.save(model_path)
        print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'template_id': template_id,
            'train_acc': float(train_acc),
            'val_acc': float(val_acc),
            'train_examples': len(X_train),
            'val_examples': len(X_val),
            'epochs': epochs,
            'timestamp': datetime.now().isoformat()
        }
        
        metadata_path = self.models_dir / f"{template_id.replace('/', '_')}_metadata.txt"
        with open(metadata_path, 'w') as f:
            for key, value in metadata.items():
                f.write(f"{key}: {value}\n")
        
        print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
        
        print(f"\n{'='*60}\n")
        
        return model
    
    def train_all(self, min_accuracy: float = 0.7):
        """
        –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ—Ö —à–∞–±–ª–æ–Ω–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            min_accuracy: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        """
        print(f"\n{'='*60}")
        print(f"üöÄ –ú–ê–°–°–û–í–û–ï –û–ë–£–ß–ï–ù–ò–ï CNN")
        print(f"{'='*60}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —à–∞–±–ª–æ–Ω—ã
        all_templates = self.learning_system.db.get_all_templates()
        
        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤: {len(all_templates)}")
        
        trained_count = 0
        skipped_count = 0
        
        for template_id in all_templates:
            stats = self.learning_system.db.get_statistics(template_id)
            
            print(f"\n{'='*60}")
            print(f"üéØ {template_id}")
            print(f"   –ü–æ–ø—ã—Ç–æ–∫: {stats['total_attempts']}")
            print(f"   –¢–µ–∫—É—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {stats['accuracy']*100:.1f}%")
            
            if stats['total_attempts'] < 50:
                print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (–º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)")
                skipped_count += 1
                continue
            
            # –û–±—É—á–∞–µ–º
            model = self.train(template_id)
            
            if model:
                trained_count += 1
            else:
                skipped_count += 1
        
        print(f"\n{'='*60}")
        print(f"üìä –ò–¢–û–ì–ò:")
        print(f"   ‚úÖ –û–±—É—á–µ–Ω–æ: {trained_count}")
        print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
        print(f"{'='*60}\n")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–µ–π')
    parser.add_argument('--template', type=str, help='ID —à–∞–±–ª–æ–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--all', action='store_true', help='–û–±—É—á–∏—Ç—å –≤—Å–µ —à–∞–±–ª–æ–Ω—ã')
    parser.add_argument('--epochs', type=int, default=50, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö')
    parser.add_argument('--batch-size', type=int, default=32, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = CNNTrainer()
    
    if args.all:
        # –û–±—É—á–∞–µ–º –≤—Å–µ
        trainer.train_all()
    elif args.template:
        # –û–±—É—á–∞–µ–º –æ–¥–∏–Ω
        trainer.train(args.template, epochs=args.epochs, batch_size=args.batch_size)
    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã:")
        all_templates = trainer.learning_system.db.get_all_templates()
        
        for i, template_id in enumerate(all_templates, 1):
            stats = trainer.learning_system.db.get_statistics(template_id)
            print(f"  {i}. {template_id} ({stats['total_attempts']} –ø–æ–ø—ã—Ç–æ–∫, {stats['accuracy']*100:.1f}% —Ç–æ—á–Ω–æ—Å—Ç—å)")
        
        if not all_templates:
            print("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤")
            print("üí° –ó–∞–ø—É—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∞–∫—Ä–æ—Å–æ–≤ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
            return
        
        try:
            choice = int(input("\n–í—ã–±–µ—Ä–∏ —à–∞–±–ª–æ–Ω (–Ω–æ–º–µ—Ä): ").strip())
            if 1 <= choice <= len(all_templates):
                template_id = all_templates[choice - 1]
                trainer.train(template_id, epochs=args.epochs, batch_size=args.batch_size)
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏ —á–∏—Å–ª–æ")


if __name__ == '__main__':
    main()
